# Day 2: Vector Spaces & Norms  

## 📌 Agenda
- Introduction to Vector Spaces  
- Basis and Dimension  
- Linear Independence & Span  
- Norms (L1, L2, ∞ norm)  
- Applications in Machine Learning  

## 🧾 Key Concepts  

### 🔹 Vector Spaces  
- A **vector space** is a collection of vectors that can be scaled and added together, following certain rules (axioms).  
- Examples:  
  - ℝ² → 2D vectors like (x, y)  
  - ℝ³ → 3D vectors like (x, y, z)  
  - Polynomial functions  

### 🔹 Basis and Dimension  
- **Basis**: A set of vectors that are linearly independent and span the entire vector space.  
- **Dimension**: The number of vectors in the basis.  

### 🔹 Linear Independence  
- Vectors are linearly independent if none of them can be written as a linear combination of the others.  

### 🔹 Norms  
Norms measure the **size/length** of a vector.  

### 🔹 Why Norms Matter in ML?  
- Used in **regularization** (L1 → Lasso, L2 → Ridge).  
- Measure error or distance in optimization.  
- Feature scaling and normalization.  
