# Day 36 â€“ Cross Validation (K-Fold CV)

## ðŸ“Œ Concepts Covered:
- **Cross Validation** and its importance  
- **K-Fold Cross Validation**  
- **Stratified K-Fold Cross Validation**  
- **Performance Visualization using Accuracy Scores**

---

## ðŸ§¾ Cross Validation Overview

- Cross Validation helps evaluate model performance by splitting data into multiple folds.  
- It reduces overfitting by ensuring that every data point gets a chance to be in both training and testing sets.  

**Key Idea:**  
Instead of one train-test split, perform multiple splits and average the results.  

**Formula (K-Fold Mean Accuracy):**  
**Accuracy (avg) = (1 / K) Î£ Accuracyâ‚–**  
where `K` = number of folds and `Accuracyâ‚–` = accuracy for fold *k*.

---

## ðŸ§¾ Stratified K-Fold

- A variant of K-Fold used for **classification tasks**.  
- Ensures each fold has the **same class proportion** as the overall dataset.  

**Formula (Mean Stratified Accuracy):**  
**Stratified Accuracy (avg) = (1 / K) Î£ Accuracyâ‚– (with class balance)**

---

## ðŸ§¾ Visualization

- After evaluating folds, plot accuracy scores to observe model stability across different splits.  
- Helps identify performance variation between folds.

---

## ðŸ”‘ Key Insights

- **K-Fold CV:** Improves reliability of model performance estimates.  
- **Stratified K-Fold:** Handles imbalanced datasets effectively.  
- **Visualization:** Provides clarity on accuracy consistency across folds.

---
