# ðŸ“˜ Day 16: Bayes Theorem & Applications

## ðŸ“Œ Agenda
- Bayes Theorem basics  
- Law of Total Probability  
- Multiple hypotheses / normalization  
- Bayesian inference (Beta-Binomial) example  
- Prior sensitivity analysis  

---

## ðŸ§¾ Key Concepts

### ðŸ”¹ Bayes Theorem
- Bayes formula (posterior from prior and likelihood):  
  P(A|B) = (P(B|A) * P(A)) / P(B)

---

### ðŸ”¹ Law of Total Probability
- Compute evidence when multiple causes possible:  
  P(B) = Î£_i P(B|A_i) * P(A_i)

---

### ðŸ”¹ Multiple Hypotheses (normalized posterior)
- For hypotheses A1..An:  
  P(A_i|B) = (P(B|A_i) * P(A_i)) / Î£_j P(B|A_j) * P(A_j)

---

### ðŸ”¹ Bayesian Inference (Beta-Binomial for coin flips)
- Prior: Beta(alpha, beta)  
- Likelihood: Binomial( n, p ) from observed Heads/Tails  
- Posterior: Beta(alpha + Heads, beta + Tails)  
- Posterior mean:  
  E[p | Data] = (alpha + Heads) / (alpha + beta + n)

---

### ðŸ”¹ Prior Sensitivity
- Changing prior (alpha,beta) affects posterior when data is limited:
  - Weak prior (e.g., Beta(1,1)) â†’ data dominates  
  - Strong prior (e.g., Beta(50,50)) â†’ prior dominates until lots of data

---
